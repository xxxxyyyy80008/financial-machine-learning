{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tabnet hyperparamter tuning with hyperopt - regression\n",
    "\n",
    "reference: \n",
    "\n",
    "- https://github.com/dreamquark-ai/tabnet/blob/develop/regression_example.ipynb\n",
    "- https://arxiv.org/pdf/1908.07442.pdf\n",
    "- http://hyperopt.github.io/hyperopt/\n",
    "- \n",
    "\n",
    "#### steps:\n",
    "1. download market data using yfinance: download S&P 500 ('^GSPC')\n",
    "1. create target variable: calculate return 20-day max return (i.e. target in supervised learning problem).\n",
    "   - for each date (T):\n",
    "      - calculate the max price change in next 20 trading dates: price_change = (max{close price in T+1 to T+20} - {close price on T})/({close price on T})\n",
    "1. feature engineering: engineer a few features\n",
    "    - lag21: previous 21 day target\n",
    "    - lag31: previous 31 day target\n",
    "    - lag41: previous 41 day target\n",
    "    - day price change: the difference between open and closing prices\n",
    "        - (Close - Open)/Open\n",
    "    - day max price change: the difference between high and low prices\n",
    "        - (High-Low)/Open\n",
    "    - one day close price change: day T close price versus day T-1 close price.\n",
    "        - 100*({Close on T} - {Close on T-1})/{Close on T-1}\n",
    "    - 10 day close price change: day T close price versus day T-10 close price.\n",
    "        - 100*({Close on T} - {Close on T-10})/{Close on T-10}\n",
    "    - 20 day close price change: day T close price versus day T-20 close price.\n",
    "        - 100*({Close on T} - {Close on T-20})/{Close on T-20}\n",
    "    - one day/10day/20day volume change\n",
    "1. processing data and split data into training and testing subsets\n",
    "1. setup the hyperparamter search space. \n",
    "  - the search space is defined based on 1) hyperparamters defined on [this page](https://dreamquark-ai.github.io/tabnet/generated_docs/README.html#model-parameters) and the search space described in TabNet original [paper](https://arxiv.org/pdf/1908.07442.pdf)\n",
    "  - I also added max number of epoches to search space, and I am not using any early stop (the early stop parametr in TabNet is `patience` - Number of consecutive epochs without improvement before performing early stopping.\n",
    "1. use hyperopt to run the tuning process\n",
    "  - I use tpe algorithm  - it is a Baysian search process with certain number of initial random trials.\n",
    "  - here is a full walkthrough of hyperopt [pdf](https://iopscience.iop.org/article/10.1088/1749-4699/8/1/014008)\n",
    "1. save trials and results \n",
    "- dump trials into a pickle file. this file can be helpful if I later want to run more trials of hyperparamter tuning.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from datetime import datetime, timedelta\n",
    "import yfinance as yf #to download stock price data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pytorch_tabnet.tab_model import TabNetClassifier\n",
    "\n",
    "import torch\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import accuracy_score\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "import os\n",
    "from pathlib import Path\n",
    "import shutil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#initiate random seed\n",
    "rand_seed=568\n",
    "import random\n",
    "def init_seed(random_seed):\n",
    "    \n",
    "    random.seed(random_seed)\n",
    "    os.environ['PYTHONHASHSEED'] = str(random_seed)\n",
    "    np.random.seed(random_seed)\n",
    "    torch.manual_seed(random_seed)\n",
    "    \n",
    "    if torch.cuda.is_available():\n",
    "        torch.cuda.manual_seed(random_seed)\n",
    "        torch.cuda.manual_seed_all(random_seed)\n",
    "        torch.backends.cudnn.deterministic = True\n",
    "        torch.backends.cudnn.benchmark = False\n",
    "        \n",
    "init_seed(rand_seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "from plotly.subplots import make_subplots"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### download S&P 500 price data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "^GSPC (19721, 7) 1927-12-30 00:00:00\n"
     ]
    }
   ],
   "source": [
    "ticker = '^GSPC'\n",
    "cur_data = yf.Ticker(ticker)\n",
    "hist = cur_data.history(period=\"max\")\n",
    "print(ticker, hist.shape, hist.index.min())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Open</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Close</th>\n",
       "      <th>Volume</th>\n",
       "      <th>Dividends</th>\n",
       "      <th>Stock Splits</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2000-01-03</th>\n",
       "      <td>1469.250000</td>\n",
       "      <td>1478.000000</td>\n",
       "      <td>1438.359985</td>\n",
       "      <td>1455.219971</td>\n",
       "      <td>931800000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2000-01-04</th>\n",
       "      <td>1455.219971</td>\n",
       "      <td>1455.219971</td>\n",
       "      <td>1397.430054</td>\n",
       "      <td>1399.420044</td>\n",
       "      <td>1009000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2000-01-05</th>\n",
       "      <td>1399.420044</td>\n",
       "      <td>1413.270020</td>\n",
       "      <td>1377.680054</td>\n",
       "      <td>1402.109985</td>\n",
       "      <td>1085500000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2000-01-06</th>\n",
       "      <td>1402.109985</td>\n",
       "      <td>1411.900024</td>\n",
       "      <td>1392.099976</td>\n",
       "      <td>1403.449951</td>\n",
       "      <td>1092300000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2000-01-07</th>\n",
       "      <td>1403.449951</td>\n",
       "      <td>1441.469971</td>\n",
       "      <td>1400.729980</td>\n",
       "      <td>1441.469971</td>\n",
       "      <td>1225200000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   Open         High          Low        Close      Volume  \\\n",
       "Date                                                                         \n",
       "2000-01-03  1469.250000  1478.000000  1438.359985  1455.219971   931800000   \n",
       "2000-01-04  1455.219971  1455.219971  1397.430054  1399.420044  1009000000   \n",
       "2000-01-05  1399.420044  1413.270020  1377.680054  1402.109985  1085500000   \n",
       "2000-01-06  1402.109985  1411.900024  1392.099976  1403.449951  1092300000   \n",
       "2000-01-07  1403.449951  1441.469971  1400.729980  1441.469971  1225200000   \n",
       "\n",
       "            Dividends  Stock Splits  \n",
       "Date                                 \n",
       "2000-01-03          0             0  \n",
       "2000-01-04          0             0  \n",
       "2000-01-05          0             0  \n",
       "2000-01-06          0             0  \n",
       "2000-01-07          0             0  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df=hist[hist.index>='2000-01-01'].copy(deep=True)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### create the target variable: calcualte max return in next 20 trading days"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Open</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Close</th>\n",
       "      <th>Volume</th>\n",
       "      <th>Dividends</th>\n",
       "      <th>Stock Splits</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2000-01-03</th>\n",
       "      <td>1469.250000</td>\n",
       "      <td>1478.000000</td>\n",
       "      <td>1438.359985</td>\n",
       "      <td>1455.219971</td>\n",
       "      <td>931800000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2000-01-04</th>\n",
       "      <td>1455.219971</td>\n",
       "      <td>1455.219971</td>\n",
       "      <td>1397.430054</td>\n",
       "      <td>1399.420044</td>\n",
       "      <td>1009000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2000-01-05</th>\n",
       "      <td>1399.420044</td>\n",
       "      <td>1413.270020</td>\n",
       "      <td>1377.680054</td>\n",
       "      <td>1402.109985</td>\n",
       "      <td>1085500000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   Open         High          Low        Close      Volume  \\\n",
       "Date                                                                         \n",
       "2000-01-03  1469.250000  1478.000000  1438.359985  1455.219971   931800000   \n",
       "2000-01-04  1455.219971  1455.219971  1397.430054  1399.420044  1009000000   \n",
       "2000-01-05  1399.420044  1413.270020  1377.680054  1402.109985  1085500000   \n",
       "\n",
       "            Dividends  Stock Splits  \n",
       "Date                                 \n",
       "2000-01-03          0             0  \n",
       "2000-01-04          0             0  \n",
       "2000-01-05          0             0  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#for each stock_id, get the max close in next 20 trading days\n",
    "price_col = 'Close'\n",
    "roll_len=20\n",
    "new_col = 'next_20day_max'\n",
    "target_list = []\n",
    "\n",
    "df.sort_index(ascending=True, inplace=True)\n",
    "df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_next20dmax=df[[price_col]].shift(1).rolling(roll_len).max()\n",
    "df_next20dmax.columns=[new_col]\n",
    "df = df.merge(df_next20dmax, right_index=True, left_index=True, how='inner')\n",
    "\n",
    "df.dropna(how='any', inplace=True)\n",
    "df['target']= 100*(df[new_col]-df[price_col])/df[price_col]  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    5479.000000\n",
       "mean        2.450897\n",
       "std         4.077561\n",
       "min        -3.743456\n",
       "25%         0.135604\n",
       "50%         1.130147\n",
       "75%         3.318523\n",
       "max        44.809803\n",
       "Name: target, dtype: float64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['target'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "df['target'].hist(bins=100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### engineer features\n",
    "\n",
    "- lag21: previous 21 day target\n",
    "- lag31: previous 31 day target\n",
    "- lag41: previous 41 day target\n",
    "- day price change: the difference between open and closing prices\n",
    "    - (Close - Open)/Open\n",
    "- day max price change: the difference between high and low prices\n",
    "    - (High-Low)/Open\n",
    "- one day close price change: day T close price versus day T-1 close price.\n",
    "    - 100*({Close on T} - {Close on T-1})/{Close on T-1}\n",
    "- 10 day close price change: day T close price versus day T-10 close price.\n",
    "    - 100*({Close on T} - {Close on T-10})/{Close on T-10}\n",
    "- 20 day close price change: day T close price versus day T-20 close price.\n",
    "    - 100*({Close on T} - {Close on T-20})/{Close on T-20}\n",
    "- one day/10day/20day volume change\n",
    "    \n",
    "  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Open</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Close</th>\n",
       "      <th>Volume</th>\n",
       "      <th>Dividends</th>\n",
       "      <th>Stock Splits</th>\n",
       "      <th>next_20day_max</th>\n",
       "      <th>target</th>\n",
       "      <th>lag21</th>\n",
       "      <th>...</th>\n",
       "      <th>lag41</th>\n",
       "      <th>open_close_diff</th>\n",
       "      <th>day_change</th>\n",
       "      <th>day_max_change</th>\n",
       "      <th>oneday_change</th>\n",
       "      <th>10day_change</th>\n",
       "      <th>20day_change</th>\n",
       "      <th>oneday_volchange</th>\n",
       "      <th>10day_volchange</th>\n",
       "      <th>20day_volchange</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2000-02-01</th>\n",
       "      <td>1394.459961</td>\n",
       "      <td>1412.489990</td>\n",
       "      <td>1384.790039</td>\n",
       "      <td>1409.280029</td>\n",
       "      <td>981000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1465.150024</td>\n",
       "      <td>3.964435</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>14.820068</td>\n",
       "      <td>1.06</td>\n",
       "      <td>1.99</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2000-02-02</th>\n",
       "      <td>1409.280029</td>\n",
       "      <td>1420.609985</td>\n",
       "      <td>1403.489990</td>\n",
       "      <td>1409.119995</td>\n",
       "      <td>1038600000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1465.150024</td>\n",
       "      <td>3.976243</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.160034</td>\n",
       "      <td>-0.01</td>\n",
       "      <td>1.21</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2000-02-03</th>\n",
       "      <td>1409.119995</td>\n",
       "      <td>1425.780029</td>\n",
       "      <td>1398.520020</td>\n",
       "      <td>1424.969971</td>\n",
       "      <td>1146500000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1465.150024</td>\n",
       "      <td>2.819712</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>15.849976</td>\n",
       "      <td>1.12</td>\n",
       "      <td>1.93</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows × 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                   Open         High          Low        Close      Volume  \\\n",
       "Date                                                                         \n",
       "2000-02-01  1394.459961  1412.489990  1384.790039  1409.280029   981000000   \n",
       "2000-02-02  1409.280029  1420.609985  1403.489990  1409.119995  1038600000   \n",
       "2000-02-03  1409.119995  1425.780029  1398.520020  1424.969971  1146500000   \n",
       "\n",
       "            Dividends  Stock Splits  next_20day_max    target  lag21  ...  \\\n",
       "Date                                                                  ...   \n",
       "2000-02-01          0             0     1465.150024  3.964435    NaN  ...   \n",
       "2000-02-02          0             0     1465.150024  3.976243    NaN  ...   \n",
       "2000-02-03          0             0     1465.150024  2.819712    NaN  ...   \n",
       "\n",
       "            lag41  open_close_diff  day_change  day_max_change  oneday_change  \\\n",
       "Date                                                                            \n",
       "2000-02-01    NaN        14.820068        1.06            1.99              0   \n",
       "2000-02-02    NaN        -0.160034       -0.01            1.21              0   \n",
       "2000-02-03    NaN        15.849976        1.12            1.93              1   \n",
       "\n",
       "            10day_change  20day_change  oneday_volchange  10day_volchange  \\\n",
       "Date                                                                        \n",
       "2000-02-01           NaN           NaN                 0              NaN   \n",
       "2000-02-02           NaN           NaN                 1              NaN   \n",
       "2000-02-03           NaN           NaN                 1              NaN   \n",
       "\n",
       "            20day_volchange  \n",
       "Date                         \n",
       "2000-02-01              NaN  \n",
       "2000-02-02              NaN  \n",
       "2000-02-03              NaN  \n",
       "\n",
       "[3 rows x 21 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['lag21']=df['target'].shift(21)\n",
    "df['lag31']=df['target'].shift(31)\n",
    "df['lag41']=df['target'].shift(41)\n",
    "\n",
    "df['open_close_diff'] = df['Close'] - df['Open']\n",
    "df['day_change']=(100*df['open_close_diff']/df['Open']).round(2)\n",
    "df['day_max_change'] = (100*(df['High'] - df['Low'])/df['Open']).round(2)\n",
    "\n",
    "#create a binary feature: 1 day change\n",
    "#0: decrease; 1: increase\n",
    "df['oneday_change']=(df['Close'].diff()>0)+1-1\n",
    "\n",
    "df['10day_change']=df['Close'].diff(10)\n",
    "df['20day_change']=df['Close'].diff(20)\n",
    "\n",
    "\n",
    "df['oneday_volchange']=(df['Volume'].diff()>0)+1-1\n",
    "\n",
    "df['10day_volchange']=df['Volume'].diff(10)\n",
    "df['20day_volchange']=df['Volume'].diff(20)\n",
    "\n",
    "\n",
    "df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "df['day_change'].hist(bins=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       " 0    5095\n",
       "-1     210\n",
       " 1     174\n",
       "Name: day_change_cat, dtype: int64"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#convert day_change into categorical feature\n",
    "#above 2- class 1; below -2 - class -1, in the middle - class0\n",
    "df['day_change_cat']=0\n",
    "df.loc[df['day_change']<=-2, 'day_change_cat']=-1\n",
    "df.loc[df['day_change']>=2, 'day_change_cat']=1\n",
    "df['day_change_cat'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5438, 22) 2000-03-30 00:00:00\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Open</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Close</th>\n",
       "      <th>Volume</th>\n",
       "      <th>Dividends</th>\n",
       "      <th>Stock Splits</th>\n",
       "      <th>next_20day_max</th>\n",
       "      <th>target</th>\n",
       "      <th>lag21</th>\n",
       "      <th>...</th>\n",
       "      <th>open_close_diff</th>\n",
       "      <th>day_change</th>\n",
       "      <th>day_max_change</th>\n",
       "      <th>oneday_change</th>\n",
       "      <th>10day_change</th>\n",
       "      <th>20day_change</th>\n",
       "      <th>oneday_volchange</th>\n",
       "      <th>10day_volchange</th>\n",
       "      <th>20day_volchange</th>\n",
       "      <th>day_change_cat</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2000-03-30</th>\n",
       "      <td>1508.520020</td>\n",
       "      <td>1517.380005</td>\n",
       "      <td>1474.630005</td>\n",
       "      <td>1487.920044</td>\n",
       "      <td>1193400000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1527.459961</td>\n",
       "      <td>2.657395</td>\n",
       "      <td>4.533823</td>\n",
       "      <td>...</td>\n",
       "      <td>-20.599976</td>\n",
       "      <td>-1.37</td>\n",
       "      <td>2.83</td>\n",
       "      <td>0</td>\n",
       "      <td>29.450073</td>\n",
       "      <td>106.160034</td>\n",
       "      <td>1</td>\n",
       "      <td>-288900000.0</td>\n",
       "      <td>-5200000.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2000-03-31</th>\n",
       "      <td>1487.920044</td>\n",
       "      <td>1519.810059</td>\n",
       "      <td>1484.380005</td>\n",
       "      <td>1498.579956</td>\n",
       "      <td>1227400000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1527.459961</td>\n",
       "      <td>1.927158</td>\n",
       "      <td>4.339390</td>\n",
       "      <td>...</td>\n",
       "      <td>10.659912</td>\n",
       "      <td>0.72</td>\n",
       "      <td>2.38</td>\n",
       "      <td>1</td>\n",
       "      <td>34.109985</td>\n",
       "      <td>89.409912</td>\n",
       "      <td>1</td>\n",
       "      <td>-67700000.0</td>\n",
       "      <td>77100000.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2000-04-03</th>\n",
       "      <td>1498.579956</td>\n",
       "      <td>1507.189941</td>\n",
       "      <td>1486.959961</td>\n",
       "      <td>1505.969971</td>\n",
       "      <td>1021700000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1527.459961</td>\n",
       "      <td>1.426987</td>\n",
       "      <td>2.309865</td>\n",
       "      <td>...</td>\n",
       "      <td>7.390015</td>\n",
       "      <td>0.49</td>\n",
       "      <td>1.35</td>\n",
       "      <td>1</td>\n",
       "      <td>49.339966</td>\n",
       "      <td>114.689941</td>\n",
       "      <td>0</td>\n",
       "      <td>100900000.0</td>\n",
       "      <td>-7300000.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows × 22 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                   Open         High          Low        Close      Volume  \\\n",
       "Date                                                                         \n",
       "2000-03-30  1508.520020  1517.380005  1474.630005  1487.920044  1193400000   \n",
       "2000-03-31  1487.920044  1519.810059  1484.380005  1498.579956  1227400000   \n",
       "2000-04-03  1498.579956  1507.189941  1486.959961  1505.969971  1021700000   \n",
       "\n",
       "            Dividends  Stock Splits  next_20day_max    target     lag21  ...  \\\n",
       "Date                                                                     ...   \n",
       "2000-03-30          0             0     1527.459961  2.657395  4.533823  ...   \n",
       "2000-03-31          0             0     1527.459961  1.927158  4.339390  ...   \n",
       "2000-04-03          0             0     1527.459961  1.426987  2.309865  ...   \n",
       "\n",
       "            open_close_diff  day_change  day_max_change  oneday_change  \\\n",
       "Date                                                                     \n",
       "2000-03-30       -20.599976       -1.37            2.83              0   \n",
       "2000-03-31        10.659912        0.72            2.38              1   \n",
       "2000-04-03         7.390015        0.49            1.35              1   \n",
       "\n",
       "            10day_change  20day_change  oneday_volchange  10day_volchange  \\\n",
       "Date                                                                        \n",
       "2000-03-30     29.450073    106.160034                 1     -288900000.0   \n",
       "2000-03-31     34.109985     89.409912                 1      -67700000.0   \n",
       "2000-04-03     49.339966    114.689941                 0      100900000.0   \n",
       "\n",
       "            20day_volchange  day_change_cat  \n",
       "Date                                         \n",
       "2000-03-30       -5200000.0               0  \n",
       "2000-03-31       77100000.0               0  \n",
       "2000-04-03       -7300000.0               0  \n",
       "\n",
       "[3 rows x 22 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.dropna(how='any', inplace=True)\n",
    "print(df.shape, df.index.min())\n",
    "df.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####  categorical data processing for TabNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "target='target'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.dropna(how='any', inplace=True)\n",
    "train = df.copy(deep=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "day_change_cat 3\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'day_change_cat': 3}"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "categorical_columns = ['day_change_cat']\n",
    "categorical_dims =  {}\n",
    "for col in categorical_columns:\n",
    "    print(col, train[col].nunique())\n",
    "    l_enc = LabelEncoder()\n",
    "    train[col] = l_enc.fit_transform(train[col].values)\n",
    "    \n",
    "    categorical_dims[col] = len(l_enc.classes_)\n",
    "\n",
    "categorical_dims"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(['day_change_cat'], {'day_change_cat': 3})"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "categorical_columns, categorical_dims"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#####  Define categorical features for categorical embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "unused_feat = ['Dividends', 'Stock Splits', 'next_20day_max',\n",
    "               'open_close_diff', 'day_change' ]\n",
    "\n",
    "features = [ col for col in train.columns if col not in unused_feat+[target]] \n",
    "\n",
    "cat_idxs = [ i for i, f in enumerate(features) if f in categorical_columns]\n",
    "\n",
    "cat_dims = [ categorical_dims[f] for i, f in enumerate(features) if f in categorical_columns]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Open', 'High', 'Low', 'Close', 'Volume', 'lag21', 'lag31', 'lag41', 'day_max_change', 'oneday_change', '10day_change', '20day_change', 'oneday_volchange', '10day_volchange', '20day_volchange', 'day_change_cat'] 16\n"
     ]
    }
   ],
   "source": [
    "print(features, len(features))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[15]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cat_idxs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[3]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cat_dims"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Split data from training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5438, 22)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = train[features].values[:-1000,:]\n",
    "y_train = train[target].values[:-1000]\n",
    "\n",
    "\n",
    "X_test = train[features].values[-950:, ]\n",
    "y_test = train[target].values[-950:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((4438, 16), (950, 16))"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape, X_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####  hyperopt setup - define search space and score function\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "from hyperopt import hp\n",
    "from hyperopt import fmin, tpe, hp, STATUS_OK, Trials, anneal, rand"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "search_space = { \n",
    "    \n",
    "                 'n_d': hp.choice('n_d',[8, 16, 24, 32, 64, 128]), #Nd and Na are chosen from {8, 16, 24, 32, 64, 128},\n",
    "                 'n_steps': hp.choice('n_steps',[3,4,5,6,7,8,9,10]),#Nsteps is chosen from {3, 4, 5, 6, 7, 8, 9, 10}\n",
    "                 'gamma':hp.choice('gamma', [1.0, 1.2, 1.5, 2.0]),#γ is chosen from {1.0, 1.2, 1.5, 2.0}\n",
    "                 'n_independent':hp.choice('n_independent', [1,2,3,4,5] ),\n",
    "                 'n_shared':hp.choice('n_shared', [1,2,3,4,5]),\n",
    "                 'momentum':  hp.choice('momentum', np.round(np.arange(0.01, 0.4, 0.01),3)), #Momentum for batch normalization, typically ranges from 0.01 to 0.4 (default=0.02)\n",
    "                 #momentum mB., and mB is chosen from {0.6, 0.7, 0.8, 0.9, 0.95, 0.98}. \n",
    "                 'lambda_sparse': hp.choice('lambda_sparse', [0, 0.000001, 0.0001, 0.001, 0.01, 0.1]), #λsparse is chosen from {0, 0.000001, 0.0001, 0.001, 0.01, 0.1}\n",
    "                 'optimizer_fn': hp.choice('optimizer_fn', ['Adam', 'RMSprop', 'SGD']),\n",
    "                 'lr': hp.choice('lr', [0.005, 0.01, 0.02, 0.025]), #optimizer. the learning rateis chosen from {0.005, 0.01.0.02, 0.025}, \n",
    "                 'optimizer_momentum': hp.choice('optimizer_momentum', [0.4, 0.8, 0.9, 0.95]),#optimizer ????\n",
    "                 #the decay rate is chosen from {0.4, 0.8, 0.9, 0.95} and the decay iterations is chosen from {0.5k, 2k, 8k, 10k, 20k}\n",
    "                 'weight_decay':hp.choice('weight_decay', [0, 0.5, 0.001, 0.0001] ),#optimizer.  the decay rate is chosen from {0.4, 0.8, 0.9, 0.95} a\n",
    "                 'scheduler_fn':hp.choice('scheduler_fn', ['StepLR', 'CosineAnnealingWarmRestarts', 'ReduceLROnPlateau']),\n",
    "                 'fn_step_size':hp.choice('fn_step_size', [3, 5, 10, 15]), \n",
    "                 'fn_gamma':hp.choice('fn_gamma', np.round(np.arange(0.1, 0.95, 0.01),3)),\n",
    "                 'fn_T_0':hp.choice('fn_T_0', [3, 5, 10, 15]), \n",
    "                 'fn_eta_min':hp.choice('fn_eta_min', np.round(np.arange(0.0001, 0.001, 0.0001),4)),\n",
    "                 'max_epochs':hp.choice('max_epochs', range(30, 201, 1)),\n",
    "                 'batch_size':hp.choice('batch_size', [256, 512, 1024, 2048, 4096, 8192, 16384, 32768]),#B is chosen from {256, 512, 1024, 2048, 4096, 8192, 16384, 32768}\n",
    "                 'virtual_batch_size':hp.choice('virtual_batch_size', [256, 512, 1024, 2048, 4096]),#BV is chosen from {256, 512, 1024, 2048, 4096}\n",
    "                 'patience':hp.choice('patience', [0]),\n",
    "                  }\n",
    "\n",
    "n_trials = 100\n",
    "n_random_trials = 30"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pytorch_tabnet.tab_model import TabNetRegressor\n",
    "import torch\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import label_binarize\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import copy\n",
    "\n",
    "def score(params):\n",
    "    \n",
    "    tab_params = {}\n",
    "    tab_params['n_d'] = params['n_d']\n",
    "    tab_params['n_a'] = params['n_d'] #set n_a equals n_d according to official document\n",
    "    tab_params['seed']= rand_seed #set random seed for reproduciablity\n",
    "    tab_params['gamma'] = params['gamma']\n",
    "    tab_params['n_independent'] = params['n_independent']\n",
    "    tab_params['n_shared'] = params['n_shared']\n",
    "    tab_params['momentum'] = params['momentum']\n",
    "    tab_params['lambda_sparse'] = params['lambda_sparse']\n",
    "    tab_params['cat_idxs']=cat_idxs #no categorical features\n",
    "    tab_params['cat_dims']=cat_dims\n",
    "    tab_params['cat_emb_dim']=1,\n",
    "    \n",
    "    lr =params['lr']\n",
    "    weight_decay =params['weight_decay']\n",
    "    optimizer_momentum =params['optimizer_momentum']\n",
    "    optimizer_fn=params['optimizer_fn']\n",
    "    \n",
    "    if optimizer_fn=='Adam':\n",
    "        tab_params['optimizer_params'] = dict(lr=lr, weight_decay=weight_decay)\n",
    "        tab_params['optimizer_fn'] = torch.optim.Adam\n",
    "    elif optimizer_fn == 'RMSprop':\n",
    "        tab_params['optimizer_params'] = dict(lr=lr, momentum=optimizer_momentum, weight_decay=weight_decay)\n",
    "        tab_params['optimizer_fn'] = torch.optim.RMSprop\n",
    "    elif optimizer_fn == 'SGD':\n",
    "        tab_params['optimizer_params'] = dict(lr=lr, momentum=optimizer_momentum, weight_decay=weight_decay)\n",
    "        tab_params['optimizer_fn'] = torch.optim.SGD\n",
    "   \n",
    "    scheduler_fn = params['scheduler_fn']\n",
    "    fn_step_size = params['fn_step_size']\n",
    "    fn_gamma = params['fn_gamma']\n",
    "    fn_T_0 = params['fn_T_0']\n",
    "    fn_eta_min = params['fn_eta_min']\n",
    "    \n",
    "    if scheduler_fn== 'StepLR':\n",
    "        tab_params['scheduler_params'] ={'gamma':fn_gamma, 'step_size':fn_step_size}\n",
    "        tab_params['scheduler_fn'] = torch.optim.lr_scheduler.StepLR\n",
    "    elif scheduler_fn== 'CosineAnnealingWarmRestarts':\n",
    "        tab_params['scheduler_params'] ={'T_0':fn_T_0, 'eta_min':fn_eta_min}\n",
    "        tab_params['scheduler_fn'] = torch.optim.lr_scheduler.CosineAnnealingWarmRestarts\n",
    "    elif scheduler_fn== 'ReduceLROnPlateau':\n",
    "        tab_params['scheduler_params'] ={'mode':'min', 'min_lr':fn_eta_min}\n",
    "        tab_params['scheduler_fn'] = torch.optim.lr_scheduler.ReduceLROnPlateau\n",
    "        \n",
    "    tab_params['epsilon']=1e-15 #default. leave untouched\n",
    "    tab_params['verbose']=0 #no verbose\n",
    "    \n",
    "    batch_size=params['batch_size'] \n",
    "    mini_batch_size=params['virtual_batch_size'] \n",
    "    if mini_batch_size>batch_size:\n",
    "        mini_batch_size=batch_size\n",
    "    \n",
    "    #--add fit params---\n",
    "    full_params = copy.deepcopy(tab_params)\n",
    "    \n",
    "    max_epochs = params['max_epochs']\n",
    "    patience = params['patience']\n",
    "    full_params['max_epochs'] = max_epochs\n",
    "    full_params['batch_size'] = batch_size\n",
    "    full_params['virtual_batch_size'] = mini_batch_size\n",
    "    full_params['patience'] = patience\n",
    "    \n",
    "    params_list.append(copy.deepcopy(full_params)) \n",
    "    \n",
    "    #-----------------------------------------------------\n",
    "    #---start training: this part can easily be replaced with k-fold list----\n",
    "    \n",
    "    i = len(params_list)\n",
    "    \n",
    "    \n",
    "    #initiate classifier - need to re-initiate for each Train-Test pair\n",
    "    clf = TabNetRegressor(**tab_params)\n",
    "    clf.fit(\n",
    "        X_train=X_train, y_train=y_train.reshape(-1,1),\n",
    "        eval_set=[(X_train, y_train.reshape(-1,1))],\n",
    "        eval_name=['train'],\n",
    "        eval_metric=['mse'],\n",
    "        max_epochs=max_epochs, patience=patience,\n",
    "        batch_size=batch_size, virtual_batch_size=mini_batch_size,\n",
    "        num_workers=0,\n",
    "        drop_last=False\n",
    "    ) \n",
    "\n",
    "    preds = clf.predict(X_test).flatten()\n",
    "    #print(preds)\n",
    "    loss = mean_squared_error(y_pred=preds, y_true=y_test)\n",
    "\n",
    "    \n",
    "        \n",
    "    df_pred = pd.DataFrame({'y_true':y_test, 'y_pred':preds})\n",
    "    \n",
    "    metric_list.append([i, full_params, loss] )\n",
    "    df_pred.to_csv(save_dir.joinpath(f'trial_{i}'), sep='|', index=False, compression='bz2')\n",
    "    \n",
    "    \n",
    "    return {'loss': loss, 'status': STATUS_OK}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "from functools import partial\n",
    "def optimize(space, evals, cores, trials, optimizer=tpe.suggest, random_state=1234, n_startup_jobs=50):\n",
    "    space['seed']= random_state\n",
    "    algo = partial(optimizer, n_startup_jobs=n_startup_jobs)\n",
    "    best = fmin(score, space, algo=algo, max_evals=evals, trials = trials)\n",
    "    return best"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### run hyperparamter tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "params_list = []\n",
    "metric_list = []\n",
    "trials = Trials()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_dir=Path('hyper_tune/tabnet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No early stopping will be performed, last training weights will be used.                                               \n",
      "No early stopping will be performed, last training weights will be used.                                               \n",
      "No early stopping will be performed, last training weights will be used.                                               \n",
      "No early stopping will be performed, last training weights will be used.                                               \n",
      "No early stopping will be performed, last training weights will be used.                                               \n",
      "No early stopping will be performed, last training weights will be used.                                               \n",
      "No early stopping will be performed, last training weights will be used.                                               \n",
      "No early stopping will be performed, last training weights will be used.                                               \n",
      "No early stopping will be performed, last training weights will be used.                                               \n",
      "No early stopping will be performed, last training weights will be used.                                               \n",
      "100%|███████████████████████████████████████████████| 10/10 [25:39<00:00, 153.91s/trial, best loss: 11.542633152981768]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'batch_size': 6,\n",
       " 'fn_T_0': 0,\n",
       " 'fn_eta_min': 7,\n",
       " 'fn_gamma': 5,\n",
       " 'fn_step_size': 0,\n",
       " 'gamma': 3,\n",
       " 'lambda_sparse': 0,\n",
       " 'lr': 1,\n",
       " 'max_epochs': 30,\n",
       " 'momentum': 38,\n",
       " 'n_d': 1,\n",
       " 'n_independent': 1,\n",
       " 'n_shared': 3,\n",
       " 'n_steps': 4,\n",
       " 'optimizer_fn': 1,\n",
       " 'optimizer_momentum': 0,\n",
       " 'patience': 0,\n",
       " 'scheduler_fn': 2,\n",
       " 'virtual_batch_size': 3,\n",
       " 'weight_decay': 1}"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "optimize(search_space,\n",
    "          evals = 10,\n",
    "          optimizer=tpe.suggest,\n",
    "          cores = 4,\n",
    "          trials = trials, random_state=rand_seed, \n",
    "          n_startup_jobs=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### save trials and results \n",
    "\n",
    "- dump trials into a pickle file. this file can be helpful if I later want to run more trials of hyperparamter tuning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "WindowsPath('hyper_tune')"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "save_dir.parent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['hyper_tune\\\\tabnet.pkl']"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import joblib\n",
    "joblib.dump(trials, save_dir.parent.joinpath('tabnet.pkl'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(metric_list, columns=['trial_id', 'params', 'loss']).to_excel(save_dir.parent.joinpath('tabnet.xlsx'))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
